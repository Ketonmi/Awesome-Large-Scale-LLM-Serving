# Awesome-Large-Scale-LLM-Serving

![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg) [![LICENSE](https://img.shields.io/github/license/Xnhyacinth/Awesome-LLM-Long-Context-Modeling)](https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving/blob/main/LICENSE) [![commit](https://img.shields.io/github/last-commit/Ketonmi/Awesome-Large-Scale-LLM-Serving?color=blue)](https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving/commits/main/) [![PR](https://img.shields.io/badge/PRs-Welcome-red)](https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving/pulls) [![GitHub Repo stars](https://img.shields.io/github/stars/Ketonmi/Awesome-Large-Scale-LLM-Serving)](https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving)


ðŸ”¥ Must-read papers for managing llm serving clusters.



This repository contains papers on **optimizing the efficiency of large language model (LLM) serving clusters**, including request scheduling, auto-scaling, and serverless computing-oriented storage optimization and communication optimization techniques. 

Papers on large language model cluster management typically involve optimizations from multiple perspectives simultaneously. For example, they may jointly optimize request scheduling and resource allocation. **We categorize these papers based on their primary focus.**

We sincerely welcome everyone to collect papers presented at top-tier conferences in the fields of systems and artificial intelligence and submit pull requests.



## Contents

1. [Request & Job Scheduling](#request-job-scheduling)
2. [Resource Management](#resource-management)
3. [Serverless LLM Serving](#serverless-llm-serving)
4. [Prefill-Decoding Disaggregation](#prefill-decoding-disaggregation)
5. [Communication Optimization](#communication-optimization)



## ðŸ“œ Papers

> You can directly click on the title to jump to the corresponding PDF link location

### <span id="request-job-scheduling">1. Request & Job Scheduling</span>

*Scheduling online requests and offline jobs*



### <span id="resource-management">2. Resource Management</span>

*Autoscaling and placement of LLM serving instances*



### <span id="serverless-llm-serving">3. Serverless LLM Serving</span>

*Accelerating LLM loading and service startup*



### <span id="prefill-decoding-disaggregation">4. Prefill-Decoding Disaggregation</span>

*Enhancing p/d disaggregation-based LLM serving*



### <span id="communication-optimization">5. Communication Optimization</span>

*Optimizing transmission of KV Cache*



## Acknowledgements

Please contact me if I miss your name on the list, and I will add you back ASAP!

### Contributors

<a href="https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Ketonmi/Awesome-Large-Scale-LLM-Serving"/>

### Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Ketonmi/Awesome-Large-Scale-LLM-Serving&type=Timeline)](https://github.com/Ketonmi/Awesome-Large-Scale-LLM-Serving/stargazers)

